# 模式识别实验(一)实验报告

## 学生信息

- 姓名-学号-班级
- 李欢欢-2020904302-2020240402
- 刘易行-2020905896-2020240401

## 实验题目

![image-20221004152612980](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004152612980.png)

## 问题回答

### (a)分类器是如何设计的？

1. 数据的读取
   - 我们将书本上的样本点数据存入excel表格进行处理，并通过xlrd库进行读取
   - 表格设计为四列30行，从左至右列的含义依次为x1,x2,x3,所属类别wi(i=1,2,3)
   - ![image-20221004152750926](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004152750926.png)
   - ![image-20221004153358042](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153358042.png)
2. 分类器设计
   - 由题目信息我们得知`p(w1)=p(w2)=0.5` 且`p(w3)=0`，那么就说明了在考虑数据时无需考虑第三类别的数据，只需要考虑w1和w2对应的数据，那么在设计分类器时，根据`公式49`，依次使用numpy计算出公式的每一项，矩阵的均值，矩阵的协方差，然后带入求解比较判别函数的值即可解决二分类问题
   - 例如在只考虑x1单维度特征值的情况下，我们依次计算出公式所需数据如下：
   - ![image-20221004153105874](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153105874.png)
   - 哪一类别的判别函数值大，那么则将其归为哪一类，并与表格第四列对应的标签比对，判定分类结果是否正确，并将其统计到`count_false`和`count_true`
   - ![image-20221004153250240](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153250240.png)
   - ![image-20221004152907310](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004152907310.png)

### (b、c)分别选取一个（两个、三个）特征的情况下的经验训练误差以及Bhattacharyya界

- 经验训练误差与Bhattacharyya界
  - 一个特征
    - ![image-20221004153555453](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153555453.png)
  - 两个特征
    - ![image-20221004153609857](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153609857.png)
  - 三个特征
    - ![image-20221004153626250](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153626250.png)
- 图像分析（放到了同一张图中）
  - ![image-20221004153702479](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221004153702479.png)

（f)对比、分析、总结

- 对比
  - 通过实验结果我们发现 经验训练误差分别为`[0.3 , 0.45, 0.15]`,Bhattacharyya界为`[0.47399944, 0.46046616, 0.41192563]`
- 分析
  - 我们发现，对于一有限数据集，有可能在更高的数据维数下训练误差会增加，原因是否有可能是各个特征值之间彼此并不独立，存在着某种联系，导致着经验训练误差出现了波动
- 总结
  - 此次实验是本学期模式识别课程的第一次实验，在此前的课程中，受限于没有纸质书本以及线上课程的影响，对于模式识别这门课的理解和掌握并不算很到位，网课效果也不是很好，但是通过本次实验，我们小组在进一步巩固Python科学计算能力与编码水平的同时，对于模式识别的含义以及分类问题和贝叶斯决策论有了更深一步的认识，通过实践操作去理解原理并掌握的感觉很棒，印象也很深，尽管刚一拿到本实验题目时我们两人都陷入了一筹莫展的窘境，但随着我们二人之间的大量研讨与学习，我们逐步对于实验问题以及要解决的问题有了清晰的认识，将大问题拆解为一个个的小模块，并开始策划分工，组织分模块编码与测试，最终圆满完成了本次实验，并于9月29日课程中向老师进行了初步的演示，在老师的指导下，证实了我们的思路的正确性以及学习成果，并于10月4日最终完成此次实验，收益颇丰。

## 实验分工

- 注：本次实验全过程为小组两人课余时间以及国庆假期内自习时一并研讨完成
- 李欢欢
  - 贝叶斯决策论原理学习、研讨
  - 实验整体思路敲定、模块划分、分类器的设计
  - 数据的读取方式以及读取数据相关代码、excel表格的设计以及后续的处理操作
  - numpy库的学习，编码实现了计算均值函数`get_u()`、计算协方差函数`get_sigmal(x)`、数据读取函数`get_data()`、分类器函数 `ClassifyTest(di)`
  - Debug，解决了数据类型不统一的重大问题，将数据类型统一为 `np.matrix`
  - 实验报告的撰写
- 刘易行
  - 贝叶斯决策论原理学习、研讨
  - 实验整体思路敲定、模块划分、分类器的设计
  - matplotlib库的学习使用，编码实现、绘图函数 `draw()`
  - Bhattacharyya的计算函数 `get_Bhattacharyya(u1,u2,sigmal1,sigmal2,pw1,pw2,d)`、、判别函数`get_gi()、`,分类器函数 `ClassifyTest(di)`
  - Debug，优化代码，解决了多特征值计算时的np.shape()不统一的问题
  - 注释撰写
  - 实验报告的撰写

## 实验源代码

- 编码过程使用Jupyter编写
- 后统一为一个python文件

```python
import numpy as np  # 计算数据
import matplotlib.pyplot as plt  # 绘制图线
import xlrd  # 读取数据


# 均值计算函数 计算出u
def get_u(x):
    u = np.mean(x, axis=0)  # 计算每一列的均值u
    return u


# 计算协方差矩阵 sigmal
def get_sigmal(x):
    sigmal = np.cov(np.mat(x).T)
    return sigmal


# 根据式(49)计算判别函数的值
def get_gi(x, u, sigmal, pw, d):
    # 将各个数据转换为np.array矩阵形式
    x = np.mat(x)
    u = np.mat(u)
    sigmal = np.mat(sigmal)
    pw = np.mat(pw)

    # 根据公式49计算判别函数的值
    g = -0.5 * (x - u) * sigmal.I * (x - u).T - d / 2 * np.log(2 * np.pi) - 0.5 * np.log(
        np.linalg.det(sigmal)) + np.log(pw)
    return g


def get_data():
    x = []  # 存放最终的数据
    data = xlrd.open_workbook("data.xls")  # 加载表格文件
    table = data.sheets()[0]  # 选取工作簿 sheet1
    rows = table.nrows  # 表格的总行数
    for i in range(0, rows):  # 遍历每一行读取数据
        row_value = table.row_values(i)
        print("row value={}".format(row_value))
        if row_value[3] != 3:  # x3不需要添加进去因为p(x3)=0
            x.append(row_value)
    print("----------------------")
    print("------数据读取完毕------")
    print("----------------------")
    print("")
    print("")
    return x


def get_Bhattacharyya(u1, u2, sigmal1, sigmal2, pw1, pw2, d):
    # 计算Bhattacharyya界的值

    # 数据类型归一为np.matrix
    sigmal1 = np.mat(sigmal1)
    sigmal2 = np.mat(sigmal2)
    u1 = np.mat(u1)
    u2 = np.mat(u2)

    # 数据验证 便于纠错
    print("-------Bhattacharyya参数验证--------")
    print("parameter and their type:")
    print("u1:", u1, "type:", type(u1))
    print("u2:", u2, "type:", type(u2))
    print("sigmal1:", sigmal1, "type:", type(sigmal1))
    print("sigmal2:", sigmal2, "type:", type(sigmal2))
    print("pw1:", pw1, "type:", type(pw1))
    print("pw2:", pw2, "type:", type(pw2))
    print("d:", d, "type:", type(d))
    if d == 1:
        k_half = (1 / 8) * (u2 - u1).T * ((sigmal1 + sigmal2) / 2).I * (u2 - u1) + (1 / 2) * np.log(
            np.linalg.det((sigmal1 + sigmal2) / 2) / np.sqrt(np.linalg.det(sigmal1) * np.linalg.det(sigmal2)))
    else:
        k_half = (1 / 8) * (u2 - u1) * ((sigmal1 + sigmal2) / 2).I * (u2 - u1).T + (1 / 2) * np.log(
            np.linalg.det((sigmal1 + sigmal2) / 2) / np.sqrt(np.linalg.det(sigmal1) * np.linalg.det(sigmal2)))

    # 由公式(76)算出Perror
    Perror = np.sqrt(np.array(pw1 * pw2)) * np.exp(-k_half)
    print("-------Bhattacharyya计算完毕--------")
    print("------------------------------------")
    print("")
    print("")
    return Perror


def ClassifyTest(di):
    # 分类器函数 参数di为特征维度值
    d = di  # 特征维度
    g = [0, 0, 0]
    pw = (0.5, 0.5, 0)  # 先验概率
    u = [0, 0, 0]  # 各个维度的均值
    sigmal = [0, 0, 0]  # 各个维度的协方差矩阵
    count_true = 0
    count_false = 0
    num = 0
    data = get_data()  # 读取数据

    #     print("类型",type(np.mat(sigmal[0])))
    #     print(type(sigmal[0]))
    #     print("sigmal1",sigmal[0])
    for i in range(len(pw) - 1):
        xi = [x[:d] for x in filter(lambda x: x[3] == i + 1, data)]  # 获得每一个类别的对应特征
        u[i] = get_u(xi)
        sigmal[i] = get_sigmal(xi)
        print("i={}".format(i))
        print("第{}个特征对应的参数".format(i + 1))
        print("xi={}".format(xi))
        print("ui={}".format(u[i]))
        print("sigmali={}".format(sigmal[i]))
        print("----------------")
        print("")
        print("")

    Bbound = get_Bhattacharyya(u[0], u[1], sigmal[0], sigmal[1], pw[0], pw[1], d)
    for i in range(len(data)):
        if i % 2 == 0:
            num += 1
        print("第{}个样本点".format(num))
        x = data[i][:d]
        w = data[i][3]
        print("x = ", x)
        g[0] = get_gi(x, u[0], sigmal[0], pw[0], d)
        g[1] = get_gi(x, u[1], sigmal[1], pw[1], d)
        print("g1(x) ={}".format(g[0]), "g2(x) ={}".format(g[1]))
        if g[0] > g[1]:  # 根据判别函数的值去进行比对分类
            flag = w == 1
            print("w1", flag)
        else:
            flag = w == 2
            print("w2", flag)
        if flag:
            count_true += 1
        else:
            count_false += 1
    error_rate = (count_false) / (count_true + count_false)
    print("经验训练误差：{}".format(error_rate))
    print("Bhattacharyya={}".format(Bbound))
    print("")
    print("")
    return error_rate, Bbound


def draw(data1, data2):
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']  # 显示中文
    plt.title("Naive Bayes Lab1", fontdict={'fontname': 'comic sans MS', 'fontsize': 20})
    plt.xlabel('Dimension')
    plt.ylabel('Error')
    x = range(1, 4)

    # plt.figure(figsize=(20, 8), dpi=80)

    plt.plot(x, data1, label='经验训练误差', color='orange', linestyle=":", linewidth=1)
    plt.plot(x, data2, label='Bhattacharyya', color='cyan', linestyle="-.")
    plt.legend()
    plt.savefig("Bayes.png")
    plt.show()


def main():
    print("一维度二分类问题：")
    oneData = ClassifyTest(1)
    print("二维度二分类问题：")
    twoData = ClassifyTest(2)
    print("三维度二分类问题：")
    threeData = ClassifyTest(3)

    errorVec = np.array([oneData[0], twoData[0], threeData[0]])
    BboundVec = np.array([float(oneData[1]), float(twoData[1]), float(threeData[1])])

    draw(errorVec, BboundVec)


main()
```

## 实验结果

### 数据读取

![image-20221011122430920](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122430920.png)

### 一个特征维度

![image-20221011122453581](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122453581.png)

![image-20221011122517641](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122517641.png)

### 两个特征维度

![image-20221011122544394](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122544394.png)

### 三个特征维度

![image-20221011122607748](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122607748.png)

### 实验图表分析

![image-20221011122634233](https://happygoing.oss-cn-beijing.aliyuncs.com/img/image-20221011122634233.png)

# 请老师批评指正！